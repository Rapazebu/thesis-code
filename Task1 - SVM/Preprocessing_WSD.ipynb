{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing_WSD.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN9+e66PbA3Cpzxq5JyiUrB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["We're at task 1, in the unlikely hypothesis that it can be lauched automatically on all the acceptable patterns.\n","Here I describe the preprocessing of the data, from the file \"TPAS_corpus.json\" to the pandas dataframe that will be used to feed the SVM classifier."],"metadata":{"id":"MsV1nUwnxgc_"}},{"cell_type":"markdown","source":["\n","\n","1.   Get a dictionary \n","\n","```\n","D = {v1 : {1 : [s1, s2, s3, ...], \n","          {2 : [s1, s2, s3, ...],\n","           3 : [s1, s2, s3, ...]}\n","     v2 : {1 : [s1, s2, s3, ...],\n","           2 : [s1, s2, s3, ...]}\n","     v3 : {1 : [s1, s2, s3, ...], \n","           2 : [s1, s2, s3, ...]}\n","          }\n","```\n","\n","2.   Filter all verbs with more than three/four patterns acceptable \n","\n","3.   Lemmatize so as to get a list `Ls = [(token, sentence), (token, sentence), ...]`\n","\n"],"metadata":{"id":"yRmCRmqFtXY1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_htgjH5htR5x"},"outputs":[],"source":["# reads the file and returns the dict\n","\n","def RitornaDict(filename):\n","  return []\n","\n","# filters the dict based on how many patterns per verbs do you want\n","\n","def FiltraDict(D, n):\n","  return []"]},{"cell_type":"markdown","source":["Extract contextual embedding of the verb"],"metadata":{"id":"kPpA3KzZzaJs"}},{"cell_type":"code","source":["# copypaste code snippet from the SVM notebook \n","#modify only the main() function + add a function that returns the dataframe\n","\n","\n","def RitornaEmbedding(sentence, token, layers = None):\n","  return[]"],"metadata":{"id":"Rdy8f6yuwFwK"},"execution_count":null,"outputs":[]}]}