{"cells":[{"cell_type":"markdown","metadata":{"id":"6C7KWl2eAZf9"},"source":["# Preprocessing, extracting and averaging embeddings"]},{"cell_type":"markdown","metadata":{"id":"NfBZuxoo4TH0"},"source":["Here we are at task 2, \"easy\" choice: we extract an average of contextualized embeddings of the verb for each pattern, and then cluster these averages. Compare this classification with the one made on static embeddings (https://github.com/Rapazebu/Clustering-Verb-Meanings-in-Italian)"]},{"cell_type":"markdown","metadata":{"id":"6wfIX0f95T0C"},"source":["Install and import stuff"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3319,"status":"ok","timestamp":1652361853396,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"3E4iAu134Syo","outputId":"a088ed0d-adb4-42b6-876e-c7971a138c1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\marta\\anaconda3\\lib\\site-packages (4.18.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n","Requirement already satisfied: sacremoses in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (0.0.49)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (0.5.1)\n","Requirement already satisfied: filelock in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: six in c:\\users\\marta\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in c:\\users\\marta\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in c:\\users\\marta\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1652361915533,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"zqP_3XA6K6o1","outputId":"93da27db-fa56-401b-98ba-d9ca19c4f927"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: simplemma in c:\\users\\marta\\anaconda3\\lib\\site-packages (0.6.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install simplemma"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8176,"status":"ok","timestamp":1652361933799,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"Rg7es659O_pu"},"outputs":[],"source":["import json \n","import pandas as pd \n","import numpy as np \n","import simplemma\n","import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","import nltk \n","from nltk.stem import SnowballStemmer\n","from codecs import *"]},{"cell_type":"markdown","metadata":{"id":"La3YK11dPBel"},"source":["Clustering contextualized embeddings gathered by sense. \n","\n","Steps:\n","\n","1.   Filtro pattern con + di 30 istanze: `Ps = [abbaiare_1, abbaiare_2 ecc]`\n","2.   A ogni frase se pattern è accettabile appendo il token lemmatizzato e l'embedding: \n","`Ls = [label, sentence, token, embedding]`\n","3.   Per ogni label appendo la media di vettori: \n","`Vs = [(abbaiare_1, np.average(vettore1, vettore2, vettore3), (abbaiare2, media) ecc]`\n","4. Metto tutto in un pandas dataframe\n","5.   Do i suddetti vettori in pasto al kmeans (lo stesso che ho usato per embeddings statici\n","6. Comparo qualitativamente e bang il clustering sui vettori è fatto\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1652361940838,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"guL1WP-bapxB"},"outputs":[],"source":["def ReturnDatabase(filename):\n","    f = open(filename)\n","    r = json.load(f)\n","    data = r['data']\n","    dataClean = []\n","    for x in data: \n","        if x[1] != 'x' and x[1] != 'u' and '.' not in x[1] and '_' not in x[0]:\n","            dataClean.append(x)\n","    return dataClean\n","\n","def count(dataClean):\n","  patterns = {}\n","  for x in dataClean:\n","    pattern = (x[0], x[1])\n","    if pattern not in patterns: \n","       patterns[pattern] = 1\n","    else: \n","       patterns[pattern]  = patterns[pattern] + 1  \n","  return patterns #(abbaiare,1): 3, (abbaiare,2): 5\n","\n","def getsentences(data, patterns):\n","  Ls = []\n","  for x in data: \n","    tup = (x[0], x[1])\n","    if patterns[tup] > 30:\n","      trip = (x[0], x[1], x[2])\n","      Ls.append(trip)\n","  return Ls\n","\n","def gettokens_SIMPLEMMA(Ls):\n","  Ms = []\n","  langdata = simplemma.load_data('it')\n","  for x in Ls: \n","    sentence = x[2].split(\" \")\n","    for tok in sentence:\n","      lemmatized = simplemma.lemmatize(tok, langdata)\n","      if lemmatized == x[0]:\n","        tup = (x[0], x[1], tok, x[2])\n","        Ms.append(tup)\n","        break\n","  return Ms\n","\n","def gettokens_SNOWBALL(Ls):\n","  Ms = []\n","  stemmer_snowball = SnowballStemmer('italian')\n","  for x in Ls: \n","    sentence = x[2].split(\" \")\n","    verb_stem = stemmer_snowball.stem(x[0])\n","    for tok in sentence:\n","      tok_stem = stemmer_snowball.stem(tok)\n","      #print(tok, tok_stem)\n","      if tok_stem == verb_stem:\n","        tup = (x[0], x[1], tok, x[2])\n","        Ms.append(tup)\n","        break\n","  return Ms\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1652361945471,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"bKhIFVFjjfCJ"},"outputs":[],"source":["# get embeddings \n"," \n","def get_word_idx(sent: str, word: str):\n","     return sent.split(\" \").index(word)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def get_hidden_states(encoded, token_ids_word, model, layers):\n","     \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n","        Select only those subword token outputs that belong to our word of interest\n","        and average them.\"\"\"\n","     with torch.no_grad():\n","         output = model(**encoded)\n"," \n","     # Get all hidden states\n","     states = output.hidden_states\n","     # Stack and sum all requested layers\n","     output = torch.stack([states[i] for i in layers]).sum(0).squeeze().to(device)\n","     # Only select the tokens that constitute the requested word\n","     word_tokens_output = output[token_ids_word]\n","     return word_tokens_output.mean(dim=0)\n"," \n","def get_word_vector(sent, idx, tokenizer, model, layers):\n","     \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n","        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n","     encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\").to(device)\n","     # get all token idxs that belong to the word of interest\n","     token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n","     return get_hidden_states(encoded, token_ids_word, model, layers)\n"," \n","def main(sent, tok, layers=None):\n","     # Use last four layers by default\n","     layers = [-4, -3, -2, -1] if layers is None else layers\n","     tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-xxl-cased\")\n","     model = AutoModel.from_pretrained(\"dbmdz/bert-base-italian-xxl-cased\", output_hidden_states=True).to(device)\n","     idx = get_word_idx(sent, tok)\n","     word_embedding = get_word_vector(sent, idx, tokenizer, model, layers).cpu()\n","     return word_embedding "]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":276,"status":"ok","timestamp":1652361950273,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"adnIVXbR5j7u"},"outputs":[],"source":["# appends the vector to the list, i. e. returns a list label, sentence, vector\n","\n","def getvectors(Ms):\n","  Ns = []\n","  for x in Ms: \n","    try:\n","      embedding = main(x[3], x[2])\n","      label = x[0] + \"_\" + x[1]\n","      print(x[3])\n","      tup = (label, x[3], embedding)\n","      Ns.append(tup)\n","    except: \n","      pass\n","  return Ns"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":254,"status":"ok","timestamp":1652361953444,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"kpXvSmn44j-2"},"outputs":[],"source":["# takes the list label-sentence-vector and creates a dictionary label:average of vectors for label\n","\n","def getaverage(Ns):\n","  d = {}\n","  for x in Ns:\n","    if x[0] not in d:\n","      d[x[0]] = [x[2]]\n","    else: \n","      d[x[0]] = d[x[0]] + [x[2]]\n","  avgs = {}\n","  for key in d:\n","    avgs[key] = [x.numpy() for x in d[key]]\n","    avg = np.mean(avgs[key], axis = 0)\n","    avgs[key] = avg\n","  return avgs\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1652361956103,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"hOEU7avf7B7P"},"outputs":[],"source":["#writing stuff\n","\n","def getmetadata(filename, Ns):\n","  d = {}\n","  # counts how many embeddings we have for each pattern\n","  for x in Ns:\n","    if x[0] not in d:\n","      d[x[0]] = 1\n","    else: \n","      d[x[0]] = d[x[0]] + 1\n","  fh = open(filename, \"w\", \"utf-8\")\n","  for x in d:\n","    fh.write(x)\n","    fh.write(\"\\t\")\n","    fh.write(str(d[x]))\n","    fh.write(\"\\n\")  \n","  fh.close()  \n","\n","def writefile(filename, avgs):\n","  fh = open(filename, \"w\", \"utf-8\")\n","  meta = [str(i) for i in range(769)]\n","  fh.write(\"label\")\n","  for x in meta:\n","    tabbed = \"\\t\" + str(x)\n","    fh.write(tabbed)\n","  fh.write(\"\\n\")\n","\n","  for x in avgs:\n","    fh.write(x)\n","    lista = [str(x +1) for x in avgs[x]]\n","    for x in lista:\n","      n = \"\\t\" + x \n","      fh.write(n)\n","    fh.write(\"\\n\")\n","  fh.close()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19207,"status":"ok","timestamp":1652361977693,"user":{"displayName":"Marta Ricchiardi","userId":"11350998013342061676"},"user_tz":-120},"id":"kedtFPMa2Yr8","outputId":"dd808063-06bd-483d-a339-bf4743ebb56d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"JI6YcksNEDts"},"source":["Ora gli facciamo computare gli embeddings, in modo che sputi fuori una lista LABEL SENTENCE EMBEDDINGS, es abbaiare_1, frase, emb:"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["data = ReturnDatabase(\"G:\\My Drive\\TESI codici\\TPAS corpus.json\") # change here\n","patterns = count(data)\n","Ls = getsentences(data, patterns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"GG8DyObh4a4q"},"outputs":[],"source":["AB = Ls[:4070]       # done\n","AF = Ls[4071:7288]   # done\n","AN = Ls[7289:13142]  \n","B = Ls[13143:15275] # done\n","CA = Ls[15276:20069] # done\n","CO = Ls[20070:25159] \n","D = Ls[25160:31353] \n","E = Ls[31354:34033] # done\n","F = Ls[34034:36770] # done\n","G = Ls[36771:38131] # done\n","I = Ls[38132:45111]\n","L = Ls[45112:46207] # done\n","M = Ls[46208:48972] # done\n","N = Ls[48973:49659] # done\n","O = Ls[49660:51542] # done\n","P = Ls[51543:63858]\n","R = Ls[63859:86199]\n","S = Ls[86200:]\n","T = Ls[:]\n","U = Ls[:]\n","V = Ls[:]\n","Z = Ls[:]\n","Ms = gettokens_SIMPLEMMA(N)      # change here\n","Ns = getvectors(Ms)   \n","avgs = getaverage(Ns) \n","writefile(\"G:\\My Drive\\TESI codici\\Vectors_N.csv\", avgs) # change here\n","getmetadata(\"G:\\My Drive\\TESI codici\\Metadata_N.csv\", Ns) # change here"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["avgs = getaverage(Ns) \n","writefile(\"G:\\My Drive\\TESI codici\\Vectors_G.csv\", avgs) # change here\n","getmetadata(\"G:\\My Drive\\TESI codici\\Metadata_G.csv\", Ns) # change here"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["writefile(\"G:\\My Drive\\TESI codici\\Vectors_AF.csv\", avgs) # change here\n","getmetadata(\"G:\\My Drive\\TESI codici\\Metadata_AF.csv\", Ns) # change here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"PREPROCESSING  averaging contextual embeddings - Copy.ipynb","version":""},"interpreter":{"hash":"f914ed65193159a8aae0183c189504cf956664f03b0bead4e3f6d9684f458302"},"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
